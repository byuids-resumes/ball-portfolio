[
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Projects/project1.html",
    "href": "Projects/project1.html",
    "title": "Client Report - Project 1",
    "section": "",
    "text": "Using the name data along with the year people can find many interesting trends including, how pop culture influences baby names, the popularity of biblical names, and often have good guesses of when someone was born based solely on the name. This data shows interesting trends in baby names over the years, and how they are influenced by different factors. However, it is important to note that an individual can’t come to a complete conclusion without further data.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#elevator-pitch",
    "href": "Projects/project1.html#elevator-pitch",
    "title": "Client Report - Project 1",
    "section": "",
    "text": "Using the name data along with the year people can find many interesting trends including, how pop culture influences baby names, the popularity of biblical names, and often have good guesses of when someone was born based solely on the name. This data shows interesting trends in baby names over the years, and how they are influenced by different factors. However, it is important to note that an individual can’t come to a complete conclusion without further data.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-1",
    "href": "Projects/project1.html#questiontask-1",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nHow does your name at your birth year compare to its use historically?\nMy name, Bethany was most popular from 1980 to 2000. Before and after that there were only a couple hundred people were given that name. However, at its height about 2,000 babies were given that name. I was born in 2004, right when the popularity of the name was dropping off.\n\n\nShow the code\nimport pandas as pd\nimport plotly.express as px\nimport ssl\nssl._create_default_https_context = ssl._create_unverified_context\n\n# Read the CSV file from the URL\nurl = \"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\"\nnames_year = pd.read_csv(url)\n\n# Filter for the name 'Bethany'\nbethany_names_year = names_year.query('name == \"Bethany\"')\n\n# Create a line plot\nbethany_plot = px.line(bethany_names_year, x = 'year', y = 'Total',\n                       labels={'Total': 'Number of babies born with the name'},\n                       title='Popularity of the name Bethany over the years')\n\n# Add a vertical line at the year 2004\nbethany_plot.add_vline(x = 2004, line_dash = \"dash\", line_color = \"red\", annotation_text = \"My birth year\",\n                       annotation_position = \"bottom left\")\n\n# Show the plot\nbethany_plot.show()\n\n\n                                                \n\n\nFindings\n-The name Bethany was rarely given to new babies until the 1950s\n-In 1988 the name was at its peek of popularity and was given to 3,294 babies.\n-In 2004 when I was born and given the name Bethany it was dropping in popularity very quickly. Only 1,614 babies were given that name.",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-2",
    "href": "Projects/project1.html#questiontask-2",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nI would guess based on probability that someone named Brittany would be born between 1985 and 1995, which would mean that as of 2024 they would be between the ages of 39 and 29. Before these years there were only about 500 babies given that name per year and after those years there were only about a thousand babies given that name per year. This may seem like a lot, but between 1985 and 1995 it was more like 30,000 per year.\n\n\nShow the code\nimport pandas as pd\nimport plotly.express as px\nimport ssl\nssl._create_default_https_context = ssl._create_unverified_context\n\n# Read the CSV file from the URL\nurl = \"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\"\nnames_year = pd.read_csv(url)\n\n# filters by name\nBrittany_names_year = names_year.query('name == \"Brittany\"')\n\n\n# Create a line plot\nBrittany_plot = px.line(Brittany_names_year, x = 'year', y = 'Total',\n                       labels={'Total': 'Number of babies born with the name'},\n                       title='Popularity of the name Brittany over the years')\n\n# shows graph\nBrittany_plot.show()\n\n\n                                                \n\n\nFindings\n-The name Brittany was rarely used only a couple of hundred babies were given that name nationwide before the 1980s.\n-The name Brittany rose very quickly starting in the 1980s and reached its peak in 1990 with 32.5K babies given that name.\n-After the peak in 1990 the popularity dropped just as quickly as it rose, leveling out in about the year 2000.\n-After the popularity dropped it stay a little higher overall before the drop of about 1,000 born with that name on average instead of about 500 before the spick. However, this increase was nowhere near where it was at its height.",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-3",
    "href": "Projects/project1.html#questiontask-3",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\nThe most apparent trend is that the popularity of all of these biblical names went down substantially in the 1970s. Another notable trend is that all of these names were most popular in the 1950s. Of these names Mary was the most popular at about 54,000 at its height of popularity, followed shortly by Paul, with about 25,000 at its height. However, both Martha and Peter were never as popular at about 11,000 at their height.\n\n\nShow the code\nimport pandas as pd\nimport plotly.express as px\nimport ssl\nssl._create_default_https_context = ssl._create_unverified_context\n\n# Read the CSV file from the URL\nurl = \"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\"\nnames_year = pd.read_csv(url)\n\n# Filters the data for the years 1920 to 2000 and for the specific names.\nnames = ['Mary', 'Martha', 'Peter', 'Paul']\nnames_year_filtered = names_year[(names_year['year'] &gt;= 1920) & (names_year['year'] &lt;= 2000) & (names_year['name'].isin(names))]\n\n# makes the graph\nfig = px.line(names_year_filtered, x = 'year', y = 'Total', color = 'name',\n              # adds captions and title\n              labels={'Total': 'Total number of babies born with name'},\n              title='Showing trends of biblical names popularity dropping in the 1970s and other trends (1920-2000)')\n\n# Customize layout\nfig.update_layout(\n    xaxis_title = 'Year',\n    legend_title_text = 'Names',\n)\n\n# Show the graph\nfig.show()\n\n\n                                                \n\n\nFindings\n-These examples of biblical names dropped in popularity significantly from the late 1950s to the early 1970s.\n-In order of popularity over the years these names rank from most to least popular: Mary, Paul, Peter, and Martha.\n-These biblical names were all at the height of their popularity around the 1950s.\n-The name Mary at its height was almost 2x as popular as the next most popular name at the time Paul.\n-After the substantial drop in 1975 all of the names stayed fairly popular at between 4 to 1 thousand names given to new babies a year.",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-4",
    "href": "Projects/project1.html#questiontask-4",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nIt is hard to say if the movie had an effect on the name’s popularity. The popularity was already going up when the movie came out, but the overall trend of the name being more popular did stay higher. However, in 1997, the year average age of the children who watched that show when it first came out were having children there first children, it was a little lower than before the movie came out. However, in the early 2000s, it picked up significantly. It is hard to say without more information if the movie caused this spick or if it was something else.\n\n\nShow the code\nimport pandas as pd\nimport plotly.express as px\nimport ssl\nssl._create_default_https_context = ssl._create_unverified_context\n\n# Read the CSV file from the URL\nurl = \"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\"\ndf = pd.read_csv(url)\n\n# Filter by the name 'Elliott'\nElliott_df = df.query('name == \"Elliott\"')\n\n# Create a line plot\nElliott_plot = px.line(Elliott_df, x = 'year', y = 'Total', labels={'Total': 'Number of babies born with the name'},\n                       title = 'Popularity of the name Elliott over the years in relation to the movie ET')\n\n# Add a vertical line at the year 1982\nElliott_plot.add_vline(x=1982, line_dash = \"dash\", line_color = \"red\", annotation_text = \"Release of E.T.\", \n                       annotation_position = \"bottom right\")\n\n# Show the plot\nElliott_plot.show()\n\n\n                                                \n\n\nFindings\n-The name Elliott’s overall trend is steadily going up from the beginning of the data to the end.\n-The name rose in popularity significantly starting in the early 2000s, and as of the data we have could continue to go up.\n-The popularity jumped when the movie came out, however, it slumped again until about 20 years later, so it is hard to say if it was the movie or some other factor that caused the significant spike in the 2000s.\n-The findings of iff the movie had an effect are somewhat inconclusive. We need more data to get a better idea of if the spick was caused by the movie or simply loosely correlated.",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project2.html",
    "href": "Projects/project2.html",
    "title": "Client Report - Project 2",
    "section": "",
    "text": "This data explores flight delays. It compares which airports have the best and worst delays. It also explores the relationship between delays and time of year, along with the percentage of delays that are weather-related.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#elevator-pitch",
    "href": "Projects/project2.html#elevator-pitch",
    "title": "Client Report - Project 2",
    "section": "",
    "text": "This data explores flight delays. It compares which airports have the best and worst delays. It also explores the relationship between delays and time of year, along with the percentage of delays that are weather-related.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-1",
    "href": "Projects/project2.html#questiontask-1",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.\nThe data was corrected, per the specifications of the task.\n\n\nShow the code\n#replaces missing or \"bad\" data with \"good\" data.\n\n#sets replacment dictionary.\nlookup = {\n    '': 'NaN',\n    -999: 'NaN',\n    '\\+': ''  \n}\ndf2 = df.replace(lookup)\n\ndf2 = df.replace(lookup, regex=True)\n\n#shows examples of \"fixed\" data.\ndf2.head(3)\n\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500\nNaN\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n2005.0\n12687\n1041\n928\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n\n\n2\nIAD\nNaN\nJanuary\n2005.0\n12381\n414\n1058\n895\n4\n61\n2430\nNaN\n70919\n35660.0\n208\n4497\n134881\n\n\n\n\n\n\n\n\nSummary\n-Data that was not present was replaced with NaN as shown on line 3, column 2 (airport_name).\n-Data that was reprecented by -999, was replaced with NaN as shown on line 1, column 7 (num_of_delays).",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-2",
    "href": "Projects/project2.html#questiontask-2",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nWhich airport has the worst delays? Discuss the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nFrom my analysis, the Chicago airport has the worst delays. It on average has the worst delays as far as average minutes delayed. It is about second when it is fairly comparable with the Atlanta airport when you compare the total number of flights to the number of delays no matter how long. Adding these two variables together clearly shows that the Chicago airport is the worst when it comes to delays.\n\n\nShow the code\n# mean of num_of_delays_total: 3437\n# mean of num_of_flights_total 16607\n# sets \"bad\" data to the average value in that catigory.\ndf['num_of_delays_total'] = df['num_of_delays_total'].where(df['num_of_delays_total'] != -999, '3437')\ndf['num_of_flights_total'] = df['num_of_flights_total'].where(df['num_of_flights_total'] != -990, '16607')\n\n# shortens ariport names for readablitly\ndf['airport_name'] = df['airport_name'].str.split(':').str[0]\n\n\n# makes chart that shows the relationship between total flights and delayed flights.\nfig = px.scatter(\n    df,\n    x = 'num_of_delays_total',\n    y = 'num_of_flights_total',\n    labels = {'value': 'Metrics'},\n    title = 'Airport Delays Summary',\n    color = 'airport_name'\n)\n\nfig.show()\n\navg_delay_time_by_airport = df.groupby('airport_name')['minutes_delayed_late_aircraft'].mean().reset_index()\n\n# Convert average delay time from minutes to hours\navg_delay_time_by_airport['avg_delay_time_hours'] = avg_delay_time_by_airport['minutes_delayed_late_aircraft'] / 60\n\n# Create a scatter plot\nfig = px.scatter(\n    avg_delay_time_by_airport,\n    x='airport_name',\n    y='avg_delay_time_hours',\n    labels={'avg_delay_time_hours': 'Average Delay Time (hours)'},\n    title='Average Delay Time at Airports',\n    color = 'airport_name'\n)\n\nfig.show()\n\n\n                                                \n\n\n                                                \n\n\nFindings\n-The Chicago airport has the worst delays overall.\n-The Atlanta airport isn’t very far behind the Chachago airport as far as bad delays.\n-The Washington DC temple has the best delays overall.\nFor Referance\nIn the charts the airport names were shorten for clearity. Below are the full names for referance.\n-Atlanta, GA: Hartsfield-Jackson Alanta Inernaional\n-Chicago, IL: Chiccago O’Hare Inernational\n-Denver, CO: Denver Inernaional\n-Salt Lake Ciy, UT: Salt Lake Ciy Inernaional\n-San Diego, CA: San Diego Inernaional\n-San Francisco, CA: San Francisco Inernaional\n-Washington, DC: Washington Dulles International",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-3",
    "href": "Projects/project2.html#questiontask-3",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nWhat is the best month to fly if you want to avoid delays of any length? Discuss the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\nThe best month to travel if you want no delays is November, closely followed by September. To figure this out I found the average number of carrier delays compared it to each month. Finding the average for each month I found makes it much clearer and easier to see the full picture of what is happening. This also helps with reader bias when they see outliers.\n\n\nShow the code\n# Replace 'n/a' with NaN\ndf['month'].replace('n/a', pd.NA, inplace=True)\n\n# Drop rows with NaN in the 'month' column\ndf.dropna(subset=['month'], inplace=True)\n\ndf['num_of_delays_carrier'] = df['num_of_delays_carrier'].str.replace(r'\\D', '', regex=True)\n\n# convert the 'num_of_delays_carrier' column to integers\ndf['num_of_delays_carrier'] = df['num_of_delays_carrier'].astype(int)\n\navg_delay_per_month = df.groupby('month')['num_of_delays_carrier'].mean().reset_index()\n\n# Define the order of months (ascending)\nmonth_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\n# Convert 'month' column to categorical with specified order\navg_delay_per_month['month'] = pd.Categorical(avg_delay_per_month['month'], categories=month_order, ordered=True)\n\n# Sort DataFrame by the categorical 'month' column\navg_delay_per_month = avg_delay_per_month.sort_values(by='month')\n\nfig = px.line(avg_delay_per_month,\n              x='month',\n              y='num_of_delays_carrier',\n              title='Average Number of Carrier Delays by Month',\n              labels={'num_of_delays_carrier': 'Average Number of Carrier Delays', 'month': 'Month'})\n\nfig.show()\n\n\n                                                \n\n\nFindings\n-November is the best month if you want to avoid all delays.\n-September is the second-best month if you want to avoid all delays.\n-The worst months for delays are June, July, and December.",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-4",
    "href": "Projects/project2.html#questiontask-4",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations:__\n100% of delayed flights in the Weather category are due to weather\n\n30% of all delayed flights in the Late-Arriving category are due to weather.\n\nFrom April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%.\nAll data has been corrected according to the desired rules given.\n\n\nShow the code\n#cleans up data\nlookup = {\n    '':'NaN',\n    -999:'NaN',\n    '+':''\n}\ndf2 = df.replace(lookup)\n\n\n#Make new column\ndf['weather_delayed_flights'] = 0\n\n\nlate_aircraft_mean = df['minutes_delayed_late_aircraft'].mean()\n\ndf['minutes_delayed_late_aircraft'].fillna(late_aircraft_mean, inplace=True)\n\ndf['weather_delayed_flights'] += df['num_of_delays_weather']\ndf['weather_delayed_flights'] += df['num_of_delays_late_aircraft'] * 0.3\n\n# print(df['weather_delayed_flights'].head())#???????\ndf2.head(5)\n\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA\nJanuary\n2005.0\n35048\n1500\nNaN\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nDenver, CO\nJanuary\n2005.0\n12687\n1041\n928\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n\n\n2\nIAD\nNaN\nJanuary\n2005.0\n12381\n414\n1058\n895\n4\n61\n2430\nNaN\n70919\n35660.0\n208\n4497\n134881\n\n\n3\nORD\nChicago, IL\nJanuary\n2005.0\n28194\n1197\n2255\n5415\n5\n306\n9178\n88691.0\n160811\n364382.0\n151\n24859\n638894\n\n\n4\nSAN\nSan Diego, CA\nJanuary\n2005.0\n7283\n572\n680\n638\n7\n56\n1952\n27436.0\n38445\n21127.0\n218\n4326\n91552\n\n\n\n\n\n\n\n\nSummary\nAll data has been corrected according to the desired rules given.",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-5",
    "href": "Projects/project2.html#questiontask-5",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 5",
    "text": "QUESTION|TASK 5\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Discuss what you learn from this graph.\nThis graph shows that overall, not many of the flights are delayed by weather. The highest percentage is SFO at a little under 0.03% of their flights are delayed by weather, and ATL as low as 0.018%. Overall weather doesn’t effect plane travel in the grand scheme of things.\n\n\nShow the code\nlookup = {\n    '':'NaN',\n    -999:'NaN',\n    '+':''\n}\ndf2 = df.replace(lookup)\n\ndf['weather_delayed_flights'] = 0\n\n\nlate_aircraft_mean = df['minutes_delayed_late_aircraft'].mean()\n\ndf['minutes_delayed_late_aircraft'].fillna(late_aircraft_mean, inplace=True)\n\ndf['weather_delayed_flights'] += df['num_of_delays_weather']\ndf['weather_delayed_flights'] += df['num_of_delays_late_aircraft'] * 0.3\n\n# print(df['weather_delayed_flights'].head())\n\n\n\n# Calculate total weather delayed flights and total flights per airport\ntotal_weather_delayed_flights = df.groupby('airport_code')['weather_delayed_flights'].sum()\ntotal_flights_per_airport = df.groupby('airport_code')['num_of_flights_total'].sum()\n\n# Calculate proportion of flights delayed by weather at each airport\nproportion_weather_delayed = total_weather_delayed_flights / total_flights_per_airport\n\n# Sort the DataFrame by values in descending order\nproportion_weather_delayed_sorted = proportion_weather_delayed.sort_values(ascending=False)\n\n# Create bar plot\nfig = px.bar(\n    x=proportion_weather_delayed_sorted.index,\n    y=proportion_weather_delayed_sorted.values,\n    title='Proportion of Flights Delayed by Weather at Each Airport',\n    labels={'x': 'Airport Code', 'y': 'Percentage of Flights Delayed by Weather'}\n)\n\nfig.show()\n\n\n                                                \n\n\nFindings\n-SFO is most affected by weather delays\n-ATL is least affected by weather delays\n-Overall a very low percentage of overall flights are affected by weather delays.\nFor Referance\n-SFO: San Francisco, CA: San Francisco International\n-IAD: Washington, DC: Washington Dulles International\n-SAN: San Diego, CA: San Diego Inernaional\n-ORD: Chicago, IL: Chiccago O’Hare Inernational\n-DEN: Denver, CO: Denver Inernaional\n-SLC: Salt Lake Ciy, UT: Salt Lake Ciy Inernaional\n-ATL: Atlanta, GA: Hartsfield-Jackson Alanta Inernaional",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Templates/DS250_Template.html",
    "href": "Templates/DS250_Template.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Uncomment the entire section to use this template\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Templates/DS350_Template.html",
    "href": "Templates/DS350_Template.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "TODO: Update with template from Paul\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/project4.html",
    "href": "Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project3.html",
    "href": "Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project5.html",
    "href": "Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "projects.html#repo-for-all-my-projects",
    "href": "projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics\n#’ — #’ title: Palmer Penguins #’ author: Norah Jones #’ date: 3/12/23 #’ format: html #’ —\nlibrary(palmerpenguins)\n#’ ## Exploring the data #’ See ?@fig-bill-sizes for an exploration of bill sizes by species.\n#| label: fig-bill-sizes #| fig-cap: Bill Sizes by Species #| warning: false library(ggplot2) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, group = species)) + geom_point(aes(color = species, shape = species), size = 3, alpha = 0.8) + labs(title = “Penguin bill dimensions”, subtitle = “Bill length and depth for Adelie, Chinstrap and Gentoo Penguins at Palmer Station LTER”, x = “Bill length (mm)”, y = “Bill depth (mm)”, color = “Penguin species”, shape = “Penguin species”)"
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics\n#’ — #’ title: Palmer Penguins #’ author: Norah Jones #’ date: 3/12/23 #’ format: html #’ —\nlibrary(palmerpenguins)\n#’ ## Exploring the data #’ See ?@fig-bill-sizes for an exploration of bill sizes by species.\n#| label: fig-bill-sizes #| fig-cap: Bill Sizes by Species #| warning: false library(ggplot2) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, group = species)) + geom_point(aes(color = species, shape = species), size = 3, alpha = 0.8) + labs(title = “Penguin bill dimensions”, subtitle = “Bill length and depth for Adelie, Chinstrap and Gentoo Penguins at Palmer Station LTER”, x = “Bill length (mm)”, y = “Bill depth (mm)”, color = “Penguin species”, shape = “Penguin species”)"
  },
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Bethany Ball",
    "section": "",
    "text": "Student at Brigham Young University Idaho."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Bethany Ball",
    "section": "Education",
    "text": "Education\nExpected 2027 Brigham Young University - Idaho, Rexburg, ID\n\n3.8 GPA"
  },
  {
    "objectID": "resume.html#related-experience",
    "href": "resume.html#related-experience",
    "title": "Bethany Ball",
    "section": "Related Experience",
    "text": "Related Experience\n\nInternships\nApril 2024 - July 2024 Weber State University Lab, Ogden, UT\n\nConducted research on payroll analytics as part of internship responsibilities.\nCommunicated with clients to gather detailed requirements for the project.\nDeveloped, adapted, or modified a suitable database schema for efficient storage of payroll data.\nEstablished connections between the company’s database and the Bureau of Labor Statistics (BLS) database schema.\nUtilized analytical techniques to calculate the risk of employee turnover attributed to insufficient pay raises.\n\n\n\nData Science Lead\nJanuary 2024 - March 2024 Data Science Society, Co-Team Leader\n\nDeveloped and implemented an attendance tracking app for multiple societies at BYU-Idaho, optimizing efficiency and accuracy in recording attendance data.\nEnsured seamless integration of the app with existing systems and workflows at BYU-Idaho, minimizing disruptions and maximizing convenience.\nImplemented robust data security measures to protect attendee information, ensuring compliance with privacy regulations.\nIntegrated basic analytical tools such as charts into the app, enabling users to visualize attendance trends and make informed decisions.\n\n\n\nData Science Team member\nSeptember 2023 - December 2023 Data Science Society, Team member\n\nSpearheaded the development of an innovative app to track critical data for the local fire department, including equipment repairs, expiration status, and ownership details, enhancing operational efficiency and compliance.\nDesigned and implemented a user-friendly dashboard within the app, enabling seamless storage and retrieval of vital information, empowering fire department personnel to access necessary data with ease.\nEngineered a robust database structure optimized for efficient data storage and retrieval, ensuring the integrity and accessibility of critical information for the fire department.\nProvided ongoing support and maintenance for the app and database structure, demonstrating a commitment to long-term partnership and continued success for the fire department."
  },
  {
    "objectID": "resume.html#service-and-work-history",
    "href": "resume.html#service-and-work-history",
    "title": "Bethany Ball",
    "section": "Service and Work History",
    "text": "Service and Work History\n2022-2024 Computer Secience tutor, NUAMES\n2015-2024 Orchard Volunteer, Ogden, UT"
  }
]